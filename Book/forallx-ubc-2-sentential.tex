%!TEX root = forallx-ubc.tex
\chapter{Sentential Logic}
\label{ch.SL}




This chapter introduces a logical language called SL.
It is a version of \emph{sentential logic}, because the basic units of the language will represent entire sentences.
(Recall from \S\ref{intro.sentences} that we're only considering declarative sentences.)
We will be concerned with translating sentences and whole arguments into SL.
This brings us to our first definition: 
  
A \define{regimentation} (also called a \define{symbolization}) of an English sentence in SL is any sentence in SL which captures (some amount of) the logical form of that English sentence.

This definition is vague, and necessarily so.
As we will see, there will typically be more than one way to regiment a sentence in English, and different regimentations may capture more or less of the English sentence's logical form.
Rather than a precise mathematical definition, regimentation (like any translation!) is a matter of degree, where some regimentations are better than others, and many may be on a par with each other.
We may then say:

A \define{regimentation} (or \define{symbolization}) of an argument in English is an argument in SL whose sentences regiment the sentences of the argument in English.

We will see a number of examples throughout this chapter, but it is good to have this definition in mind as you read, considering other ways that you might regiment the sentences and arguments in question.




\section{Sentence Letters}

In SL, capital Roman letters ($A$, $B$, $C$, etc.) are the \define{sentence letters}.
These are the basic building blocks from which complex sentences may be constructed.
Considered only as a symbol of SL, the letter `$A$' could regiment any English sentence.
So when regimenting English in SL, it is important to provide a \emph{symbolization key}.
The key provides an English language sentence for each sentence letter used in the regimentation.

For example, consider this argument:

\begin{earg}
\item[] Today is New Year's Day.
\item[] If today is New Year's Day, then people are swimming in English Bay.
\item[\therefore] People are swimming in English Bay.
\end{earg}

This is a valid argument in English.
In regimenting it, we want to preserve the logical form of the argument which makes it valid.
What happens if we replace each sentence with a letter? 
Our symbolization key would look like this:

\begin{ekey}
\item[A:]Today is New Year's Day.
\item[B:]If today is New Year's Day, then people are swimming in English Bay.
\item[C:]People are swimming in English Bay.
\end{ekey}

We could then regiment the argument in this way:

\begin{earg}
\item[] $A$
\item[] $B$
\item[\therefore] $C$
\end{earg}

This is a regimentation of the argument, but it's not a very interesting one.
In particular, our regimentation does not encode any logical connection between $A$, $B$, and $C$.
What was compelling about the original argument has been lost in translation.
Whereas the original argument was valid, the regimentation given above is not.
After all, $A$, $B$, and $C$ could be any sentences whatsoever.
Just because $A$ and $B$ are true (on a given interpretation), it does not follow that $C$ is also true (on that interpretation).\footnote{We will provide a formal definition of validity for SL in Ch.~$\ref{ch.TruthTables}$ and Ch.~$\ref{ch.SLmodels}$.}

The symbolization key provided above is by no means the only symbolization key that we could have provided.
For instance, consider the following alternative:

\begin{ekey}
\item[]Today is Christmas Day.
\item[]Tiny Tim has difficulty walking without crutches.
\item[\therefore]We're all going to die tomorrow.
\end{ekey}

A more interesting regimentation of the valid New Year's argument will show how it is different from the invalid Christmas argument.
The relevant thing about the New Year's argument is that the second premise is not just \emph{any} sentence.
Notice that the second premise contains the first premise and the conclusion \emph{as parts}.
Our symbolization key for the argument only needs to include meanings for $A$ and $C$, and we can build the second premise from those pieces.
Thus we may regiment the argument this way:

\begin{earg}
\item[] $A$
\item[] If $A$, then $C$.
\item[\therefore] $C$
\end{earg}

By making use of the English expression `If$\ldots$ then$\ldots$', we have managed to preserve enough of the logical structure of the argument in English to provide a valid regimentation.
For our formal language, we ultimately want to replace all of the English expressions with logical notation, but this is a good start.

The English sentences that can only be regimented in SL by sentence letters are called \emph{atomic sentences}.
As we will see in later chapters, the internal structure of atomic sentences may be encoded in a formal language which includes predicates and singular terms.
However, for the time being, we do not have these expressive resources at our disposal.
Instead, atomic sentences are the smallest logical joints at which we may carve while regimenting English sentences in SL.
Accordingly, the internal structure that an English sentence might have (i.e., its sub-sentential logical form) is lost when regimented by a sentence letter.
From the point of view of SL, the sentence letters are as basic as it gets.
Although the sentence letters can be used to build up more complex sentences, they cannot be taken apart.

%Atomic sentences go together to make complex sentences in much the same way that physical atoms go together to make molecules. Physical atoms were originally called `atoms' because chemists thought that they were irreducible. Chemists were wrong, and physical atoms can be split.

%It is important to remember that a symbolization key only gives the meaning of atomic sentences for purposes of translating a specific argument.

We use capital Roman alphabet letters for the sentence letters of SL.\footnote{Later on, when we come to the logic of `all' and `some', we will reserve \textit{lowercase} Roman alphabet letters for constants and variables. Hence, there is a good reason why you will be forced to capitalize on \textit{Carnap}.} 
However, there are only twenty-six such letters, and we don't want to impose this artificial limit onto our formal language.
But how many sentence letters should we include?
Any finite number would be rather arbitrary.
Thus we will take SL to include a (countably) infinite number of sentence letters.\footnote{A set is \textit{countably infinite} just in case its elements can be paired one-to-one with the natural numbers, i.e., its elements can be listed one after the other without leaving any missing.}
To achieve this, we allow atomic sentences that have a capital letter with a numeric subscript.
So we could have a symbolization key that looks like this:

\begin{ekey}
\item[A$_1$:] Aang is from the Air Nation.
\item[A$_2$:] Aang is vegetarian.
\item[A$_3$:] Aang can bend water.
\item[T$_1$:] Toph is blind.
\item[T$_2$:] Toph likes badgers.
\item[T$_3$:] Toph invented metal bending.
\end{ekey}

Keep in mind that each of these is a different atomic sentence.
Although it is often convenient (and aids memory) to use letters corresponding to the sentences' subject matters, as in the example above, no such requirement is built into the rules of SL.
There is no special relationship between $A_{1}$ and $A_{2}$, as far as SL goes.
It's just for our convenience that we might choose to make all the $A$ sentences about Aang.




\section{Connectives}

Logical connectives are used to build complex sentences from sentence letters.
There are five logical connectives in SL.
This table summarizes them.
They are explained below.

\begin{table}[h]
\center
\begin{tabular}{|c|c|c|}
\hline
symbol&what it is called&rough translation\\
\hline
\enot&negation&`It is not the case that$\ldots$'\\
\eand&conjunction&`Both$\ldots$\ and $\ldots$'\\
\eor&disjunction&`Either$\ldots$\ or $\ldots$'\\
\eif&conditional&`If $\ldots$\ then $\ldots$'\\
\eiff&biconditional&`$\ldots$ if and only if $\ldots$'\\
\hline
\end{tabular}
\end{table}

Natural languages like English are vague and imprecise, and carry many complex subtleties of meaning.
Providing a descriptive theory of these complexities belongs to linguistics, not logic.
In contrast to English, our formal language SL will be clear and precise, defined by rules that hold without exception.
This precision and universality has many advantages, but also comes at a cost: our language is artificial insofar as it's conventions are entirely stipulated, and who is to say which stipulations are the right ones to make?

The question of which logic to accept for which applications is a deep and controversial issue within philosophical logic.
Rather than attempting to settle that question here, it will be enough for our purposes here to appeal to one method by which we may evaluate competing logics: abduction.
By contrast to inductive arguments, or the deductive arguments with which we will primarily be concerned, abductive arguments draw support from the results that a theory yields.
The reason that classical logic (i.e., the sentential and quantifier logics that we will be learning) holds the majority amongst logicians and philosophers is due to its strength and simplicity, making it of great utility for a wide range of applications.

To take just one example, mathematics is almost entirely conducted in a first-order theory like the quantifier logic that we will be learning.
Although competing logics (notably intuitionistic logic) may claim to hold certain philosophical advantages, not all proofs of mathematics can be reconstructed in these terms.
By no means does this make first-order logic any kind of stopping place, for one can continue to add logical resources given broader aims than application within mathematics.
For instance, the modal logics that you would learn about in an intermediate logic course have also been shown to have powerful applications within linguistics, computer science, and philosophy, and may be naturally combined with the logics with which we will be concerned.
Rather than any kind of stopping point, the logics covered in this course make for a natural place to begin.
Once you have mastered sentential and quantifier logic, you may well wish to branch out and consider non-classical logics, as well as further extensions to the logical vocabulary covered in this course.

Despite the advantages afforded by the classical logics we will be studying, these logics will be rather artificial by comparison to the informal patterns of reasoning in English with which you are already familiar.
Consequently, the ``translations'' provided by the table above are only approximate.
We'll see some of the differences come out below.

\section{Negation}
Consider how we might regiment these sentences:
\begin{earg}
\item[\ex{not1}] Logic is hard.
\item[\ex{not2}] It is false that logic is hard.
\item[\ex{not3}] Logic isn't hard.
\end{earg}

In order to regiment sentence \ref{not1}, we will need one sentence letter.
We can provide a symbolization key:

\begin{ekey}
\item[H:]Logic is hard.
\end{ekey}

Now, sentence \ref{not1} is simply $H$. 

Since sentence \ref{not2} is obviously related to sentence \ref{not1}, we do not want to introduce a different sentence letter.
To put it partly in English, the sentence means `It is false that $H$.'
In order to regiment this, we need a symbol for logical negation.
We will use `\enot.'
Now we can regiment `Not $H$' as `$\enot H$'.
In general, `\enot' means `It is false that' or `It is not the case that'.

A sentence of this type--- one that begins with a `\enot' symbol--- is called a \define{negation}.
The sentence it negates, in this case $H$, is called the \define{negand}.

What of Sentence \ref{not3}? It looks like a more natural  way of saying the same thing as sentence \ref{not2}.
It's saying that logic isn't hard, which is just another way of negating the proposition that logic is hard.
% So sentences \ref{not2} and \ref{not3} have the same truth conditions.
In the terminology of Ch.~\ref{ch.intro}, they are logically equivalent.
So we can regiment both sentence \ref{not2} and sentence \ref{not3} as: $\enot H$.

When regimenting English sentences in SL, the word `not' is usually a pretty good clue that `\enot' will be an appropriate symbol to use.
But it's important to think about the actual meaning of the sentence, and not rely too much on which words appear in it.

\factoidbox{
For any sentence \metaA{}, a sentence can be regimented by $\enot\metaA{}$ if it can be paraphrased in English as `It is not the case that \metaA{}.'}

Consider these further examples:

\begin{earg}
\item[\ex{not4}] Rodrigo is mortal.
\item[\ex{not5}] Rodrigo is immortal.
\item[\ex{not5b}] Rodrigo is not immortal.
\end{earg}

If we let `$R$' mean `Rodrigo is mortal', then sentence \ref{not4} can be regimented as: $R$.

What about sentence \ref{not5}? Being immortal is pretty much the same as not being mortal.
So it makes sense to treat \ref{not5} as the negation of \ref{not4}, regimenting it by $\enot{R}$.

Sentence \ref{not5b} can be paraphrased as `It is not the case that Rodrigo is immortal.'
Using negation twice, we regiment this as $\enot \enot R$.
The two negations in a row each work as negations, so the sentence means `It is not the case that, it is not the case that $R$.
It is the negation of the negation of $R$.
One can negate \emph{any} sentence of SL--- even a negation--- by putting the `\enot' symbol in front of it.
It's not only for atomic sentences.
In the case of $\enot\enot R$, this is a negation whose negand is $\enot R$, which in turn is a negation whose negand is $R$.

Here is an example that illustrates some of the complexities of regimentation:

\begin{earg}
\item[\ex{not6}] Elliott is happy.
\item[\ex{not7}] Elliott is unhappy.
\end{earg}

If we let $H$ mean `Elliot is happy', then we can regiment sentence \ref{not6} as $H$.

We might be tempted to regiment sentence \ref{not7} as $\enot{H}$.
But is being unhappy the same thing as not being happy? 
No! 
Elliott might simply be meh.
If you find out that someone is not happy, you cannot infer that they are unhappy.
Hence, we shouldn't treat \ref{not7} as the negation of \ref{not6}.
If we're allowing that `unhappy' means something different from `not happy', then we need to use a different atomic sentence to regiment \ref{not7}.

But when is a negation true?
For any sentence \metaA{}: if \metaA{} is true, then \enot\metaA{} is false.
If \metaA{} is false, then \enot\metaA{} is true.
Using `1' for true and `0' for false, we can summarize this in a \emph{truth table} for negation:

\begin{center}
\begin{tabular}{c|c}
\metaA{} & \enot\metaA{}\\
\hline
1 & 0\\
0 & 1 
\end{tabular}
\end{center}

The left column shows the possible truth-values for the negand and the right column shows the corresponding truth-value of the negation.
Accordingly, the truth table given above specifies the \textit{truth conditions} for $\enot$, i.e, the conditions under which a negated sentence is true (similarly false).
By using numeral digits, we avoid any clash with our atomic sentence letters.\footnote{Note that \textit{Carnap} will not have this virtue: truth tables will use `T' for \textit{true} and `F' for \textit{false}.}
Since 1 and 0, are the only possible values that we will consider in this course, the truth table above defines a function from the truth-value of the negand to the truth-value of the negation.
We will refer to such functions from truth-values to truth-values as \textit{truth-functions}.
We will discuss truth tables at greater length in Chapter \ref{ch.TruthTables}.



\section{Conjunction}

Consider these sentences:

\begin{earg}
\item[\ex{and1}]Jessica is strong.
\item[\ex{and2}]Luke is strong.
\item[\ex{and3}]Jessica is strong and Luke is also strong.
\end{earg}

We will need separate sentence letters for \ref{and1} and \ref{and2}, so we define this symbolization key:
\begin{ekey}
\item[J:] Jessica is strong.
\item[L:] Luke is strong.
\end{ekey}

Sentence \ref{and1} is simply regimented by $J$, and sentence \ref{and2} is regimented by $L$.

Sentence \ref{and3} can be paraphrased as `$J$ and $L$.'
In order to fully regiment this sentence, we need another symbol.
We will use `\eand'.
We regiment `$J$ and $L$' as $J\eand L$.
The logical connective `\eand' is called \define{conjunction}, and $J$ and $L$ are each called \define{conjuncts}.

Notice that we make no attempt to provide a distinct symbol for `also' in sentence \ref{and3}.
Words like `both' and `also' function to draw our attention to the fact that two things are being conjoined but are not doing any further logical work.
Thus we do not need to represent `both' and `also' in SL.
Note that Sentence \ref{and3} would have meant the same thing had it simply said `Jessica is strong, and Luke is strong,' or even if we dropped the `and' entirely and used a semicolon: `Jessica is strong; Luke is strong'.

Here are some more examples:

\begin{earg}
\item[\ex{and4}]Jessica is strong and grumpy.
\item[\ex{and5}]Jessica and Matt are strong.
\item[\ex{and6}]Although Luke is strong, he is not grumpy.
\item[\ex{and7}]Matt is strong, but Jessica is stronger than Matt.
\end{earg}

Sentence \ref{and4} is a conjunction.
The sentence says two things about Jessica, so in English it is natural to use her name only once.
It might be tempting to try this when regimenting the argument: Since $J$ means `Jessica is strong', one might attempt to paraphrase sentence \ref{and4} as `$J$ and grumpy'.
But this would be a mistake.
Once we regiment part of a sentence as $J$, any further structure within the original sentence is lost.
`$J$' is just a sentence letter and SL doesn't keep track of the fact that it was intended to be about Jessica.
Moreover, `grumpy' is not a sentence; on its own it is neither true nor false.
So instead, we paraphrase sentence \ref{and4} as the conjunction $J \eand G_{1}$ where $G_{1}$ has been added to the symbolization key to regiment `Jessica is grumpy.'
More generally, we may say that:

\factoidbox{
A sentence can be regimented by ($\metaA{}\eand\metaB{}$) if it can be paraphrased in English as `Both \metaA{}, and \metaB{}.' Each of the conjuncts must be a sentence.
}

Sentence \ref{and5} says one thing about two different subjects.
It says of both Jessica and Matt that they are strong, and in English we use the word `strong' only once.
In regimenting sentences in SL, we want to make sure each conjunct is a sentence on its own, so once again, we'll paraphrase it by repeating the elements: `Jessica is strong, and Matt is strong.'
Once we add a new atomic sentence $M$ for `Matt is strong', this regiments $J\eand M$.\footnote{One might contest this claim by instead taking `Jessica and Matt' to name a plurality where `are strong' is a plural predicate. We will be overlooking such complexities which are better handled in plural logics.}

Sentence \ref{and6} is a bit more complicated.
The word `although' tends to suggest a kind of contrast between the first part of the sentence and the second part.
Nevertheless, the sentence is still telling us two things: Luke is strong, and he's not grumpy.
So we can paraphrase sentence \ref{and6} as, `\emph{Both} Luke is strong, \emph{and} Luke is not grumpy.'
The second conjunct contains a negation, so we paraphrase further: `\emph{Both} Luke is strong \emph{and} \emph{it is not the case that} Luke is grumpy.'
Letting $G_{2}$ stand for `Luke is grumpy', and we can regiment sentence \ref{and6} as $L\eand\enot G_{2}$.

Once again, this is an imperfect translation of the English sentence \ref{and6}.
That sentence suggested that there was a contrast between Luke's two properties.
Our regimentation merely says that he has both of them.
Still, it is a regimentation that preserves some of the important features of the original, specifically the logical features.
That is, the sentences says that Luke is strong, and it also says that he's not grumpy.

Sentence \ref{and7}'s use of the word `but' indicates a similar contrastive structure.
It is irrelevant for the purpose of regimenting sentences in SL, so we can paraphrase the sentence as `\emph{Both} Matt is strong, \emph{and} Jessica is stronger than Matt.
How should we regiment the second conjunct? 
We already have the sentence letters $J$ and $M$, but neither of these says anything comparative.
We need a new sentence letter.
Let $S$ mean `Jessica is stronger than Matt.'
Now the sentence may be regimented by $M \eand S$.\footnote{In Chapter~\ref{ch.QL}, we will learn an even better way to regiment relations. All in due course!}

\factoidbox{Sentences that can be paraphrased `\metaA{}, but \metaB{}' or `Although \metaA{}, \metaB{}' are best regimented using conjunction: (\metaA{}\eand\metaB{}).
}

It is important to keep in mind that the sentence letters $J$, $M$, $G_{1}$, $G_{2}$, and $S$ are atomic sentences.
Considered as symbols of SL, they have no meaning beyond being true or false.
We used $J$ and $M$ to regiment different English language sentences that are about people being strong, but this similarity is completely lost when we regiment sentences in SL.
Nor does SL recognize any particular similarity between $G_{1}$ and $G_{2}$.

For any two sentences \metaA{} and \metaB{} of SL, the conjunction \metaA{}\eand\metaB{} is true if and only if the conjuncts--- \metaA{} and \metaB{}--- are both true. We can summarize this in the \textit{truth table} for conjunction:
\begin{center}
\begin{tabular}{c|c|c}
\metaA{} & \metaB{} & $\metaA{} \eand \metaB{}$\\
\hline
1 & 1 & 1\\
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 0
\end{tabular}
\end{center}

The two left columns indicate the truth-values of the conjuncts.
Since there are four possible combinations of truth-values, there are four rows.
The conjunction is true when both conjuncts are true, and false otherwise.
Whereas negation is a function which takes one truth-value as input, and returns one truth-value as output, conjunction takes two truth-values as inputs (the truth-values of its conjuncts) and returns a single truth-value as an output. 
Thus we may say that conjunction is a \textit{binary operator}, whereas negation is a \textit{unary operator}.
Despite this difference, the truth table given above specifies the truth conditions for conjunction in a similar manner to the way we specified truth conditions for negation.
In particular, a conjunction is true just in case both of its conjuncts are true, and it is false otherwise.

Note that conjunction is commutative: \metaA{}\eand\metaB{} is logically equivalent to \metaB{}\eand\metaA{}.
Is `and' in English commutative?
Consider the following claims:

\begin{earg}
\item[\ex{and8}] Dan went home and took a shower.
\item[\ex{and9}] Dan took a shower and went home.
\end{earg}

Do these sentences mean the same thing?
Not really.
Often the order of the conjuncts suggests the temporal order of the events.
Accordingly, we may take \ref{and8} to claim that \textit{first} Dan went home, and only \textit{then} did he take a shower, whereas \ref{and9} says that these happened in the opposite order.
But what of our truth table for conjunction?

Although SL helps to identify certain logical features in English, it cannot recover everything that we might want to recover.
This doesn't mean that one cannot provide a non-commutative theory of conjunction, but we won't be providing such a theory in this course.
Rather we stipulate that the sort of conjunction that we are interested in for the purposes of this course is commutative where the truth table for conjunction encodes this stipulation.
This doesn't make the commutative theory of conjunction less interesting than a non-commutative theory.
Indeed, simplicity is a good thing, providing for broad applications where a non-commutative notion of conjunction may get in the way.

For instance, consider mathematical claims: assuming all such claims are eternal, none are before others, and so we don't need to keep track of temporal order.
Even if one were concerned to encode temporal order, getting to grips with SL and QL as we will in this course is a good place to start.







\section{Disjunction}

Consider these sentences:

\begin{earg}
\item[\ex{or1}]Denison will golf with me or he will watch movies.
\item[\ex{or2}]Either Denison or Ellery will golf with me. 
\end{earg}

For these sentences we can use this symbolization key:

\begin{ekey}
\item[D:] Denison will golf with me.
\item[E:] Ellery will golf with me.
\item[M:] Denison will watch movies.
\end{ekey}

Sentence \ref{or1} is `Either $D$ or $M$.'
To fully regiment this, we introduce a new symbol.
The sentence becomes $D \eor M$.
The `\eor' connective is called \define{disjunction}, and $D$ and $M$ are called \define{disjuncts}.
`\eor' stands for an \emph{inclusive} reading of disjunction, which means it is true if and only if \emph{at least one disjunct} is true.

Sentence \ref{or2} is only slightly more complicated.
There are two subjects, but the English sentence only gives the verb once.
We can rewrite it as `Either Denison will golf with me, or Ellery will golf with me.'
Now it may be regimented by $D \eor E$.

\factoidbox{
A sentence can be regimented by $(\metaA{}\eor\metaB{})$ if it can be paraphrased in English as `Either \metaA{}, or \metaB{}.' Each of the disjuncts must be a sentence.
}

Since $\eor$ is a symbol that we have introduced, we get to \textit{stipulate} its truth conditions.
And we stipulate that we are using inclusive or, so that $A \eor B$ is true provided that at least one disjunct is true, including the scenario where both are true.
Is this a good stipulation for how to treat `or'?
In a study of the semantics of English, it would be appropriate to pursue this question much further.
But this book is about logic, not linguistics.
Rather than concerning ourselves with describing the exact patterns by which `or' is used in English, we will be concerned to identify a formal analogue which is simpler and more consistent in its use.
Thus we have good reason to stipulate that $\eor$ is inclusive even if `or' in English is not. 

So $D \eor E$ is true if $D$ is true, if $E$ is true, or if both $D$ and $E$ are true. It is false only if both $D$ and $E$ are false. We can summarize this with the \textit{truth table} for disjunction:

\begin{center}
\begin{tabular}{c|c|c}
\metaA{} & \metaB{} & $\metaA{}\eor\metaB{}$ \\
\hline
1 & 1 & 1\\
1 & 0 & 1\\
0 & 1 & 1\\
0 & 0 & 0
\end{tabular}
\end{center}

Like conjunction, disjunction is a binary operator which takes two truth-values as inputs and returns a single truth-value as output.
The truth table above stipulates a meaning for `$\eor$' by indicating the truth conditions for $\metaA{} \eor \metaB{}$.
We may restate these succinctly by observing that $\metaA{} \eor \metaB{}$ is false when $\metaA{}$ and $\metaB{}$ are false, and true otherwise.
This makes disjunction inclusive.

Consider the following sentences:

\begin{earg}
\item[\ex{or3}] Either you will not have soup, or you will not have salad.
\item[\ex{or4}] You will have neither soup nor salad.
\item[\ex{or5}] You get soup or salad, but not both.
\end{earg}

Here's a symbolization key:

\begin{ekey}
\item[S$_1$:] You will get soup.
\item[S$_2$:] You will get salad.
\end{ekey}

Sentence \ref{or3} can be paraphrased in this way: `Either \emph{it is not the case that} you get soup, or \emph{it is not the case that} you get salad.' 
Regimentation this claim requires both disjunction and negation.
It is a disjunction of two negations: $\enot S_1 \eor \enot S_2$.

Sentence \ref{or4} also requires negation.
It can be paraphrased as, `\emph{It is not the case that} either that you get soup or that you get salad.'
In other words, it is the negation of a disjunction.
We need some way of indicating that the negation does not just negate the right or left disjunct; the entire disjunction is the negand.
In order to do this, we put parentheses around the disjunction: `It is not the case that $(S_1 \eor S_2)$.'
This becomes simply $\enot (S_1 \eor S_2)$.\footnote{A second, equivalent, way to regiment this sentence is $(\enot S_1 \eand \enot S_2)$. We'll see why this is equivalent later on. The equivalence of $\enot (A \eor B)$ and $(\enot A \eand \enot B)$ is one of De Morgan's laws.}
Notice that the parentheses are doing important work here.
The sentence $\enot S_1 \eor S_2$ would mean `Either you will not have soup, or you will have salad,' which is very different.

Sentence \ref{or5} has a more complex structure.
We can break it into two parts.
The first part says that you get soup or you get salad.
We regiment this by $(S_1 \eor S_2)$.
The second part says that you do not get both.
We can paraphrase this as, `It is not the case that you both get soup and get salad.'
Using both negation and conjunction, we may regiment this by $\enot(S_1 \eand S_2)$.
Now we just need to put the two parts together.
As we saw above, `but' can usually be regimented by conjunction.
Sentence \ref{or5} can thus be regimented by $(S_1 \eor S_2) \eand \enot(S_1 \eand S_2)$.



\section{The Material Conditional}
For the following sentences, use this symbolization key:

\begin{ekey}
\item[R:] You will cut the red wire.
\item[B:] The bomb will explode.
\end{ekey}

\begin{earg}
\item[\ex{if1}] If you cut the red wire, then the bomb will explode.
\item[\ex{if2}] The bomb will explode only if you cut the red wire.
\end{earg}

Sentence \ref{if1} can be partially regimented by `If $R$, then $B$.'
We will use the horseshoe `$\eif$' to symbolise this relationship.
The sentence becomes $R\eif B$.
The connective is called a \define{conditional}.
The sentence on the left-hand side of the conditional ($R$ in this example) is called the \define{antecedent}.
The sentence on the right-hand side ($B$) is called the \define{consequent}.

Sentence \ref{if2} is also a conditional.
Since the word `if' appears in the second half of the sentence, it might be tempting to regiment this in the same way as sentence \ref{if1}.
However, the conditional $R\eif B$ says that \emph{if} $R$, \emph{then} $B$.
It does not say that your cutting the red wire is the \emph{only} way that the bomb could explode.
Someone else might cut the wire, or the bomb might be on a timer.
The sentence $R\eif B$ does not say anything about what to expect if $R$ is false. 
Sentence \ref{if2} is different.
It says that the only conditions under which the bomb will explode are ones where you cut the red wire, i.e., if the bomb explodes, then you must have cut the wire.
As such, sentence \ref{if2} should be regimented by $B \eif R$. 

Notice though that for both sentences, we have the same antecedent/consequent pattern: the atomic sentence before the `only if' is the antecdent.
The atomic sentence after the `only if' is the consequent.
Hence, we could also write sentence \ref{if1} as `You cut the red wire only if the bomb will explode', which we would also regiment by $R\eif B$.
This is equivalent to saying `If you cut the red wire, then the bomb will explode.' 

It is important to remember that the connective `\eif' says only that, if the antecedent is true, then the consequent is true.
It says nothing about the \emph{explanatory} connection between the two events.
For instance, regimenting sentence \ref{if2} as $B \eif R$ does not mean that the bomb exploding would somehow have caused your cutting the wire.
Both sentence \ref{if1} and \ref{if2} suggest that, if you cut the red wire, your cutting the red wire would explain why the bomb exploded.
They differ on the \emph{logical} connection.
If sentence \ref{if2} were true, then an explosion would tell us that you had cut the red wire.
Without an explosion, sentence \ref{if2} tells us nothing about what you did with the red wire.

\factoidbox{
The paraphrased sentence `\metaA{} only if \metaB{}' is logically equivalent to `If \metaA{}, then \metaB{}.'
}

% Could discuss necessary and sufficient conditions here.

When the sentence `If \metaA{} then \metaB{}' is true, this means that if \metaA{} is true then so is \metaB{}.
Hence, if the antecedent \metaA{} is true but the consequent \metaB{} is false, then the conditional `If \metaA{} then \metaB{}' is false.
What is the truth-value of `If \metaA{} then \metaB{}' when \metaA{} is false or \metaB{} is true?
Suppose, for instance, that the antecedent \metaA{} happened to be false.
`If \metaA{} then \metaB{}' would then not tell us anything about the actual truth-value of the consequent \metaB{}, and at least in ordinary English it is unclear what the truth-value of `If \metaA{} then \metaB{}' would be. 

In English, the truth of conditionals often depends on what \emph{would} be the case if the antecedent \emph{were true} even if the antecedent is false.
Put otherwise, such reasoning is not truth-functional, i.e., we need to know more about the sentence in question than just its truth-value.
This poses a serious challenge for regimenting conditionals in SL.
In order to consider what the world would be like if $R$ were true, we would need to analyse what $R$ says about the world and we are quickly led into deep questions about the way the world is, laws of nature, and counterfactual reasoning--- topics for philosophy of language, metaphysics, and the philosophy of science, but not this class.
For the purposes of this course, when we replace a sentence with a sentence letter, we consider it as either true or false, but with no further content.

What we are after is a truth-function which approximates the meaning of conditional claims in English such as given in \ref{if1} and \ref{if2}.
More specifically, we want to specify the truth-value of $\metaA{}\eif\metaB{}$ as a function of the truth-values for \metaA{} and \metaB{}, and nothing else.
This is a big limitation, since there are not many truth-functions of two values out there.
In fact there are only 16.
Thus we will choose the best among them to approximate the English `If$\ldots$ then$\ldots$' construction.
We will specify this truth-function with the following truth table:

\begin{center}
\begin{tabular}{c|c|c}
\metaA{} & \metaB{} & $\metaA{}\eif\metaB{}$\\
\hline
1 & 1 & 1\\
1 & 0 & 0\\
0 & 1 & 1\\
0 & 0 & 1
\end{tabular}
\end{center}
 
The truth table given above specifies the truth conditions for sentences includeing the \textit{material conditional} $\eif$.
We may observe that when \metaA{} is false, the conditional $\metaA{}\eif\metaB{}$ is automatically true, regardless of the truth-value of \metaB{}.
If both \metaA{} and \metaB{} are true, then the conditional $\metaA{}\eif\metaB{}$ is true.
In short, $\metaA{}\eif\metaB{}$ is false if and only if \metaA{} is true and \metaB{} is false.

More than any other connective, the regimentation of the conditional in SL is a rough approximation.
It has some very counterintuitive consequences about the truth-values of conditionals.
You can see from the truth table, for example, that an SL conditional is true any time the consequent is true, no matter what the antecedent is.
(Look at lines 1 and 3 in the chart.) 
And it is also true any time the antecedent is false, no matter what the consequent is.
(Look at lines 3 and 4.) 
This is an odd consequence.
In English, some conditionals with true consequents and/or false antecedents seem clearly to be false.
For example:

\begin{earg}
\item[\ex{pmc1}] If there are no philosophy courses at MIT, then Logic I is a philosophy course at MIT.
\item[\ex{pmc2}] If this book has fewer than thirty pages, then it will win the 2023 Pulitzer prize for poetry.
\end{earg}

Both \ref{pmc1} and \ref{pmc2} seem clearly false.
But each of them, regimented in SL, would come out true.
(If this isn't obvious, it's worth taking a moment to regiment them and consider the truth table.) 
Sentences such as \ref{pmc1} and \ref{pmc2} are sometimes referred to as \textit{paradoxes for the material conditional} since their regimentations in terms of the material conditional are true.
However, such sentences are only paradoxical if we take `$\eif$' to mean what `If \ldots, then \ldots' means in English.
Not only does the material conditional \textit{not} mean what `If \ldots, then \ldots' means in English, there is no common English expression which means what the material conditional means.
Rather, the material conditional is a purely artificial piece of formal vocabulary which we have introduced, fully stipulating its meaning.
Although the material conditional only provides a very rough approximation of the `If \ldots, then \ldots' in English, who said that English has the best vocabulary for theoretical applications?
After all, mathematics is full of artificial, entirely stipulated definitions which are nevertheless of great use in part because of the clarity that we have about what they mean given their explicit definitions.

Despite the oddness of taking the regimentations of sentences such as \ref{pmc1} and \ref{pmc2} to be true, the material conditional preserves many of the most important logical features of conditionals.
Rather than trying to capture all the subtleties of conditional claims in English, the material conditional proves its worth by abstracting a simple and extremely useful conditional which we can put to work in a wide range of theoretical applications.
Indeed, the material conditional is perfectly adequate for the purposes of mathematics, and this alone covers a very important part of human reasoning.
Programming languages also make use of material conditionals, and these have provided profoundly effective and powerful applications.

The material conditional has also been precisely defined.
By contrast, there is very little in English for which we have clear definitions, and certainly not the word `if'!
Indeed, philosophers, linguists, and logicians have spent over a century developing sophisticated mathematical theories to model the behaviour of `If \ldots, then \ldots' in English, and we are still very far from any kind of conclusive theory.
Given how unclear we are about the meaning of English conditionals, `If \ldots, then \ldots' in English is difficult to rely on in theoretical applications.
By contrast, the material conditional is easy to understand completely even if it pulls apart from similar sounding claims made in English.

We will have lots of occasions to observe the utility of the material conditional throughout this course.
For now, I'll just ask you to go along with this approach to conditionals even if the material conditional sometimes seems to provide strange results.

% Note that unlike conjunction and disjunction, the conditional is \emph{asymmetrical}. You cannot swap the antecedent and consequent without changing the meaning of the sentence, because (\metaA{}\eif\metaB{}) and (\metaB{}\eif\metaA{}) are not logically equivalent.


% However, before pressing on, it is worth reflecting on some of its demerits.
% In particular, consider the following paradoxes of the material conditional:
%
% \begin{earg}
%   \item[\ex{if3}] If roses are red, then sugar is sweet.
%   \item[\ex{if4}] If Carbon has 79 protons, John is angry.
%   % \item[\ex{if4}] If Boston has its own currency, then 2+2=5.
% \end{earg}
%
% Let's say roses are red and sugar is sweet.
% Thus both the antecedent and consequent in \ref{if3} are true, and so given the truth-table for the material conditional, \ref{if3} is true.
% But this sentence is so strange; we would never assert something like \ref{if3}, and may even claim that it is false.
%
% Something similar may be said for \ref{if4}: given that Carbon does not have 79 protons, \ref{if4} is true independent of whether John is angry or not.
% More generally, \textit{any} material conditional with a false antecedent is true, for just look at the truth table for the material conditional when it's antecedent is false.
% Again, one might find this all very strange, at least when we assert such things in English.

%\begin{earg}
%\item[\ex{if3}] Everytime a bell rings, an angel earns its wings.
%\item[\ex{if4}] Bombs always explode when you cut the red wire.
%\end{earg}

%Not all sentences of the form `If$\ldots$ then$\ldots$' are conditionals. Consider this sentence:
%
%\begin{earg}
%\item[\ex{if5}] If anyone wants to see me, then I will be on the porch.
%\end{earg}
%
%If I say this, it means that I will be on the porch, regardless of whether anyone wants to see me or not --- but if someone did want to see me, then they should look for me there. If we let $P$ mean `I will be on the porch,' then sentence \ref{if5} can be regimented simply as $P$.
%

\section{Biconditional}
  \label{sec.Bicon}

Consider these sentences:
\begin{earg}
\item[\ex{iff1}] The figure on the board is a triangle only if it has exactly three sides.
\item[\ex{iff2}] The figure on the board is a triangle if it has exactly three sides.
\item[\ex{iff3}] The figure on the board is a triangle if and only if it has exactly three sides.
\end{earg}

We may then provide the following symbolization key:

\begin{ekey}
\item[T:] The figure is a triangle.
\item[S:] The figure has three sides.
\end{ekey}

Sentence \ref{iff1}, for reasons discussed above, can be regimented as $T\eif S$.

Sentence \ref{iff2} is importantly different.
It can be paraphrased as, `If the figure has three sides, then it is a triangle.'
So it can be regimented by $S\eif T$.

Sentence \ref{iff3} says that $T$ is true \emph{if and only if} $S$ is true.
This is called a \define{biconditional}, because it entails the two conditionals $S\eif T$ and $T \eif S$.
We will use `\eiff' to represent the biconditional.
Thus sentence \ref{iff3} can be regimented by $S \eiff T$.
Instead of referring to the sentence on the left-hand side of a biconditional as the antecedent and the sentence on the right-hand side as the consequent, we will refer to the sentences on either side of a biconditional as the \define{arguments} of the biconditional, where this is a general term for the sentences on which a logical connective operates.
For instance, negation takes one argument (the negand), and so is a \define{unary} sentential operator.
By contrast, all of the other logical connectives in SL take two arguments, and so are \textit{binary} sentential operators.
Of course, the arguments of a given operator have nothing to do with the arguments we might evaluate for logical validity, though we have used the same term twice.

We could easily make do without a new symbol for the biconditional.
For instance, we could regiment \ref{iff3} as $(T \eif S)\eand(S\eif T)$.
Because we could always write $(\metaA{}\eif\metaB{})\eand(\metaB{}\eif\metaA{})$ instead of $(\metaA{}\eiff\metaB{})$, we do not strictly speaking \emph{need} to introduce a new symbol for the biconditional.\footnote{If fact the only truth-function we really need is called `nand' (not-both) or the `Sheffer stroke', but doing so would be very tedious!} 
Nevertheless, logical languages often have such a symbol, and in our case SL will have one, making it easier to regiment phrases like `if and only if.'

But what are the truth-conditions for sentences like $\metaA\eiff\metaB$? 
Consider the following:

\begin{center}
\begin{tabular}{c|c|c}
\metaA{} & \metaB{} & $\metaA{}\eiff\metaB{}$\\
\hline
1 & 1 & 1\\
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{tabular}
\end{center}

The truth table above specifies truth conditions for the biconditional by taking $\metaA{} \eiff \metaB{}$ to be true if \metaA{} and \metaB{} have the same truth-value, and false if $\metaA{}$ and $\metaB{}$ have different truth-values.
Although we know that $\metaA{}$ and $\metaB{}$ will have different truth-values if $\metaA{} \eiff \metaB{}$ is false, this does not tell us whether $\metaA{}$ is true and $\metaB{}$ is false, or \textit{vice versa}.
Similarly, knowing that $\metaA \eiff \metaB$ is true does not tell us whether both $\metaA$ and $\metaB$ are true, or whether both are false. 



\section{Other Symbolization}
We have now introduced all of the connectives of SL.
We can use them together to regiment many kinds of sentences.
Consider these examples of sentences that use the English-language connective `unless', with an associated symbolization key:

\begin{earg}
\item[\ex{unless1}] Unless you wear a jacket, you will catch a cold. 
\item[\ex{unless2}] You will catch a cold unless you wear a jacket. 
\end{earg}


\begin{ekey}
\item[J:] You will wear a jacket.
\item[D:] You will catch a cold.
\end{ekey}

We can paraphrase sentence \ref{unless1} as `Unless $J$, $D$.'
This means that if you do not wear a jacket, then you will catch a cold; with this in mind, we might regiment \ref{unless1} as $\enot J \eif D$.
Intuitively, `unless $J$' means `if not $J$, then \dots'. 

This same sentence \ref{unless1} also means that if you do not catch a cold, then you must have worn a jacket.
With this in mind, we might regiment \ref{unless1} as $\enot D \eif J$.
Which of these is the correct regimentation of sentence \ref{unless1}? 

The answer is that both regimentations are correct.
% In general, sentences and arguments may have more than one regimentation, although as we saw in the previous chapter, regimentations are not always equally good.
Moreover, these sentences are logically equivalent, where one is the \textit{contrapositive} of the other: the contrapositive of $P \eif Q$ is $\enot Q \eif \enot P$, i.e. you flip the order and negate both sides.

Sentence \ref{unless2} is logically equivalent to sentence \ref{unless1}. 
It means the same thing as saying `Unless you wear a jacket, you will catch a cold.' 
Hence, it can also be regimented as either $\enot J \eif D$ or $\enot D \eif J$.
One is not better than the other.

When regimenting sentences like sentence \ref{unless1} and sentence \ref{unless2}, it is easy to get turned around.
Since the conditional is not symmetric, it would be wrong to regiment either sentence as $J \eif \enot D$.
Fortunately, there are other logically equivalent expressions.
Both sentences mean that you will wear a jacket or--- if you do not wear a jacket--- then you will catch a cold.
So we can regiment both of them as $J \eor D$.
Although linguistically less natural, this regimentation is easier to remember.
It helps that  `$Q \eor P$' is logically equivalent to `$P \eor Q$', so if you use disjunction, you don't have to worry about the order.
Thus we have:


\factoidbox{
If a sentence can be paraphrased as `Unless \metaA{}, \metaB{},' then it can be regimented as $(\enot\metaA{}\eif\metaB{})$, $(\enot\metaB{}\eif\metaA{})$, or $(\metaA{}\eor\metaB{})$.
}

The regimentation of standard sentence types is summarized on p.~\pageref{app.notation}.





\section{Sentences of SL}
\label{sec:sentencesofSL}
The sentence `Apples are red or berries are blue' is a sentence of English, and `$A\eor B$' is a sentence of SL.
Although we can identify sentences of English when we encounter them, we do not have a formal definition of `English sentence'.
Students used to learn grammarians' attempts to formalize some such rules, but contemporary linguists agree that this was a hopeless project.
Natural languages like English are just not susceptible to such precisification.
By contrast, it is possible to define what counts as a sentence in SL.
This is one respect in which a formal language like SL is more precise than a natural language like English.

Whenever a language becomes the object of study, we call the language that is being studied the \define{object language} and the language in which we are conducting our study the \define{metalanguage}. \label{def.metalanguage}
The object language we will be concerned with in this chapter is SL.
In the following section, we will provide a formal definition of the sentences of SL. 
The definition itself will be given in the metalanguage which in our case will consist of English enriched with certain amount of mathematical vocabulary, e.g., `\metaA{}' and `\metaB{}' symbols.
It is vitally important to distinguish between the object language and metalanguage, doing our best to avoid mixing them up.
In our case, we will be helped by the fact that the sentences of our object language SL are entirely formal, whereas the sentences of our metalanguage are mostly informal, though they may contain some mathematical elements.
For instance, the sentence `$A\eor B$' is a sentence in the object language SL because it only uses symbols of SL. 
In contrast, the sentence ``The expression `$A\eor B$' is a sentence of SL'' is not a sentence of SL, but rather a sentence in the metalanguage that we use to talk \emph{about} `$(A\eor B)$' which is a sentence of SL.
Now for the definition of a sentence in SL.


\subsection{Expressions}

There are three kinds of symbols in SL:

\begin{center}
\begin{tabular}{|c|c|}
\hline
sentence letters & $A,B,C,\ldots,Z$\\
with subscripts, as needed & $A_1, B_1,Z_1,A_2,A_{25},J_{375},\ldots$\\
\hline
connectives & $\enot,\eand,\eor,\eif,\eiff$\\
\hline
parentheses&( , )\\
\hline
\end{tabular}
\end{center}

We define an \define{expression of SL} as any string of symbols of SL. Take any of the symbols of SL and write them down, in any order, and you have an expression.


\subsection{Well-Formed Formulae}
\label{sec:wff}

Since any sequence of symbols is an expression, many expressions of SL will be nonsense. For example, the following expressions don't mean anything: {\color{black}they lack truth conditions. They don't even rise to the level where they might be false: they are simply meaningless.}

\begin{earg}
  \item[] \enot\enot\enot\enot
  \item[] ))\eiff
  \item[] $A_4$ \eor
\end{earg}

None of these are sentences in SL.
A grammatical expression is called a \textit{well-formed formula}.
It is common to use the acronym `wff' where the plural is `wffs'.

Atomic sentence letters like $A$ and $G_{13}$ are certainly wffs.
We can form further wffs out of these by using the various connectives.
Using negation, we can get $\enot A$ and $\enot G_{13}$.
Using conjunction, we can get $A \eand G_{13}$, $G_{13} \eand A$, $A \eand A$, and $G_{13} \eand G_{13}$.
We could also apply negation repeatedly to get wffs like $\enot \enot A$ or apply negation along with conjunction to get wffs like $\enot(A \eand G_{13})$ and $\enot(G_{13} \eand \enot G_{13})$.
The possible combinations are endless, even starting with just these two sentence letters, and there are infinitely many sentence letters.
Even though there is no point in trying to list all the wffs, we can still define the set of all wffs.

To begin with, we will describe the rules that govern the construction of wffs.
These rules will matter a great deal in our later adventures in metalogic.
Consider negation: given any wff \metaA{} of SL, $\enot\metaA{}$ is a wff of SL.
Remember, `\metaA{}' is not itself a sentence; it is a variable that stands in for any wff at all.
Since the variable `\metaA{}' is not a symbol of SL, `$\enot\metaA{}$' is not an expression of SL.
Instead, it is an expression of the metalanguage that allows us to talk about infinitely many expressions of SL.
For instance, we can say things like: For any $\metaA$, \ldots.

We can say something similar for each of the other connectives.
For instance, if \metaA{} and \metaB{} are wffs of SL, then $\metaA{}\eand\metaB{}$ is a wff of SL.
Providing clauses like this for all of the connectives, we arrive at the following formal definition for a \define{well-formed formula of SL}:

\begin{enumerate}
\item Every atomic sentence is a wff.
\item If \metaA{} and \metaB{} are any wffs, then:
	\begin{enumerate}
		\item $\enot\metaA{}$ is a wff;
		\item $(\metaA{}\eand\metaB{})$ is a wff;
		\item $(\metaA{}\eor\metaB{})$ is a wff;
		\item $(\metaA{}\eif\metaB{})$ is a wff; and
		\item $(\metaA{}\eiff\metaB{})$ is a wff.
	\end{enumerate}
\item Nothing else is a wff.
\end{enumerate}

This is a \emph{recursive} definition of the wffs of SL.
Think of building the set of wffs as follows.
In stage 0, we add all the sentence letters, calling this set $\Lambda_0$.
Then in stage 1, we take any wffs from $\Lambda_0$ and substitute them in for $\metaA{}$ and $\metaB{}$ in the rules above, adding the results to a new set $\Lambda_0'$.
We do this in all the ways that we can, adding as much to $\Lambda_0'$ as possible while limiting ourselves to the ingredients included in $\Lambda_0$ and following the rules above to form our wffs. 
Once we stop getting anything new, we then take $\Lambda_1 = \Lambda_0 \cup \Lambda_0'$ which contains all and only the wffs which belong to either $\Lambda_0$ or $\Lambda_0'$.
Now we repeat the process to build $\Lambda_2$ from $\Lambda_1$ in just the same way.
More generally, given any $\Lambda_n$ we may build $\Lambda_{n+1}$.
Although we cannot do this in \textit{time}, we can do this in \textit{math}.
That is, we consider the union $\bigcup_{n\in \mathbb{N}}\Lambda_n$ which gathers together all the members from each $\Lambda_n$ for all $n \in \mathbb{N}$.

To get another perspective on the same thing, we may define the set of wffs to be the smallest set to satisfy the rules above.
By requiring it to be the smallest such set, we are making sure that nothing else ends up a wff, like the number 2, or the Eiffel tower. 

Note that the definition of the wffs of SL is purely \emph{syntactic}.
Each rule specifies which expressions of SL is a wff.
This definition provides what linguists have struggled to provide for English: a specification once and for all of which syntactic constructions are grammatical sentences, i.e., the wffs of SL.
It is important to stress that the definition of the wffs does not tell us what the sentences of SL \emph{mean}.
We'll return to semantics in much more detail in Ch. \ref{ch.TruthTables}.
For now, our concern is with the rules for writing sequences of symbols, nothing more.

An important point is now in order: given the definition of a wff, the following sentences are not wffs of SL, and for good reason:
\begin{earg}
  \item[\ex{paren1}] $A \eand \enot B$.
  \item[\ex{paren2}] $C \eor D \eand E$.
\end{earg}
The reason that \ref{paren1} is not a wff is the boring but crucial reason that it simply lacks outermost parentheses.
Officially, a conjunction is a sentence of the form $(\metaA{} \eand \metaB{})$ for sentences $\metaA{}$ and $\metaB{}$, not a sentence of the form $\metaA{} \eand \metaB{}$.
We may also point out that at numerous places throughout this text, we have not followed the strict letter of this law: you have already seen may places where the parentheses have been dropped.
Dropping the outermost parentheses is permissible when it does not lead to any ambiguities, i.e., when there is a unique wffs which is clearly specified.
For instance, we may recover the following wff from \ref{paren1} without any ambiguity:
\begin{earg}
  \item[\ex{paren3}] $(A \eand \enot B)$.
\end{earg}
The same cannot be said for \ref{paren2}, for we have a choice between the following options:
\begin{earg}
  \item[\ex{paren4}] $((C \eor D) \eand E)$.
  \item[\ex{paren5}] $(C \eor (D \eand E))$.
\end{earg}
Apart from anything to do with their meaning, the two wffs above are different.
As it will turn out, they will also have different truth conditions, providing reason to distinguish them syntactically.
Semantics aside, it is important to be clear about what it is \textit{officially} to be a wff.
Of course, we could have defined the wffs not to include outermost parentheses, so what's the reason for this stipulation.
The answer is that without adding the parentheses, our syntax fails to keep track of the order in which a sentence has been constructed, and as a result, runs together sentences like \ref{paren4} and \ref{paren5} above, turning both back into \ref{paren2}.

It is worth computing whether a number of expressions are or are not wffs of SL.
For instance, suppose that we want to know whether or not $\enot \enot \enot D$ is a wff of SL.
Looking at the second clause of the definition, we know that $\enot \enot \enot D$ is a wff \emph{if} $\enot \enot D$ is a wff.
So now we need to ask whether or not $\enot \enot D$ is a wff.
Again looking at the second clause of the definition, $\enot \enot D$ is a wff \emph{if} $\enot D$ is.
Again, $\enot D$ is a wff \emph{if} $D$ is a wff.
Now $D$ is a sentence letter, so we know that $D$ is a wff by the first clause of the definition.
Thus $\enot \enot \enot D$ is in fact a wff. 

The connective that you look to first in decomposing a sentence is called the \define{main connective} (or \emph{outermost logical operator}) of that sentence.
For example, consider the main connective of $\enot (E \eor (F \eif G))$ which is negation, \enot.
The main connective of $\enot E \eor (F \eif G)$ is disjunction, \eor.
Conversely, if you're building up a wff from simpler sentences, the connective introduced by the last rule you apply is the main connective.
It is the connective that governs the interpretation of the entire sentence.
Being able to identify the main connective of sometimes convoluted sentences in SL is going to be an essential skill in your logical tool kit.





\subsection{Sentences}

Recall that a sentence is a meaningful expression that can be true or false.
Rather than providing a definition, this claim describes the theoretical role that sentences are intended to play.
Since the meaningful expressions of SL are the wffs and since every wff of SL is either true or false on a given interpretation, we may now define the \define{sentences} of SL to be the wffs of SL.
Not every formal language will have this nice feature.
In the language for quantifier logic (QL)--- developed later in this book--- there are wffs which are not sentences.

The recursive structure of sentences in SL will be important when we consider their truth-conditions.
The sentence $\enot \enot \enot D$ is true if and only if the sentence $\enot \enot D$ is false, and so on through the structure of the sentence until we arrive at its basic components, i.e., the sentence letters from which it was build.
For instance, $\enot \enot \enot D$ is true if and only if the atomic sentence $D$ is false.
We will return to this point in much more detail in Chapters \ref{ch.TruthTables} and \ref{ch.SLmodels}.






\subsection{Notational Conventions}
\label{SLconventions}

As already mentioned, a wff like $Q \eand R$ must officially have outermost parentheses because we might want to use this sentence to construct further, more complicated sentences which have this sentence as a part. 
For instance, if we negate $(Q \eand R)$, we get $\enot(Q \eand R)$.
If we just had $Q \eand R$ without the parentheses and put a negation in front of it, we would have $\enot Q \eand R$.
It is most natural to read this as meaning the same thing as $(\enot Q \eand R)$, something very different than $\enot(Q\eand R)$.
The sentence $\enot(Q \eand R)$ means that it is not the case that both $Q$ and $R$ are true; $Q$ might be false or $R$ might be false, but the sentence does not tell us which.
The sentence $(\enot Q \eand R)$ means specifically that $Q$ is false and that $R$ is true.
So parentheses are crucial to the meaning of the sentence.

Although strictly speaking, $Q \eand R$ is \emph{not} a sentence of SL, we will sometimes drop the parentheses to make things easier for ourselves.
We will do this in several ways.

First, we understand that $Q \eand R$ is short for $(Q \eand R)$.
As a matter of convention, we can leave off parentheses that occur \emph{around the entire sentence}.
Even though we don't always write out the outermost parentheses, we know that they really should be there.
It is important to stress that this is only possible when $Q \eand R$ occurs by itself, and not as a part of some more complex sentence. 
If we were able to drop parentheses even when some sentence occurs as a part of a bigger sentence, we would be able to turn both \ref{paren4} and \ref{paren5} into \ref{paren2}, and that is not what we want because then there would be no way to determine the main connective.

Second, it can sometimes be confusing to look at long sentences with nested sets of parentheses.
We adopt the convention of using square brackets `[' and `]' in place of parenthesis.
There is no logical difference between $(P\eor Q)$ and $[P\eor Q]$, for example.
The unwieldy sentence
  $$(((H \eif I) \eor (I \eif H)) \eand (J \eor K))$$
could then be written in the following way, omitting the outermost parentheses and using square brackets to make the inner structure easier to see:
  $$\bigl[(H \eif I) \eor (I \eif H)\bigr] \eand (J \eor K).$$
Unfortunately, the online \textit{Carnap} system will not allow you to use square brackets when working in system LogicBookSD.
\textit{Carnap} will also always add the outer parentheses which can make things a bit harder to parse.
So be careful when using that system.

Third, we will sometimes want to regiment the conjunction of three or more sentences.
For the sentence `Alice, Bob, and Candice all went to the party', suppose we adopt a regimentation where $A$ symbolises `Alice went to the party', $B$ symbolises `Bob went to the party', and $C$ symbolises `Candice went to the party.'
The definition only allows us to form a conjunction out of two sentences, so we can regiment it as $(A \eand B) \eand C$ or as $A \eand (B \eand C)$.
However, there is no reason to distinguish between these regimentation since the two are logically equivalent.
That is, there is no logical difference between the first, in which $(A \eand B)$ is conjoined with $C$, and the second, in which $A$ is conjoined with $(B \eand C)$.
So we might as well just write $A \eand B \eand C$.
As a matter of convention, we can leave out parentheses when we conjoin three or more sentences.

Fourth, a similar situation arises with multiple disjunctions.
For instance, the sentence `Either Alice, Bob, or Candice went to the party' can be regimented as $(A \eor B) \eor C$ or as $A \eor (B \eor C)$.
Since these two regimentations are logically equivalent, we may write $A \eor B \eor C$.

These latter two conventions only apply to multiple conjunctions or multiple  disjunctions.
If a series of connectives includes both disjunctions and conjunctions, then the parentheses are essential, as with $(A \eand B) \eor C$ and $A \eand (B \eor C)$.
The parentheses are also required if there is a series of conditionals or biconditionals, as with $(A \eif B) \eif C$ and $A \eiff (B \eiff C)$.

If we had given a different definition of a wff, then strings of conjunctions or disjunctions could have counted as wffs.
For instance, might have permitted $(\metaA{} \eand \ldots \eand \metaB{})$ to be a wff whenever \metaA{}, \ldots, \metaB{} are wffs.
This would have made it a little easier to regiment some English sentences, but it would have also come at the cost of making our formal language much more complicated.
In particular, we would have to keep this more complex definition in mind when we develop truth tables and a proof system.
We want a logical language that is \emph{expressively simple} and allows us to regiment easily from English, but we also want a \emph{formally simple} language for which it is relatively easy to provide semantic clauses.\footnote{As we'll see later, this is important if we want to be able to prove things \emph{about} our language.}
Adopting notational conventions is a compromise between these two competing desires.

We have adopted these rules as notational conventions, also called \textit{metalinguistic abbreviations}, not as changes to the definition of a sentence.
Strictly speaking, $A \eor B \eor C$ is still not a sentence of SL.
Instead, it is a kind of shorthand.
We write it for the sake of convenience, but we really mean the sentence $(A \eor (B \eor C))$.

Unless and until you are very confident about wffs and the use of parentheses, it is probably good advice to stick to the formal rules.
These notational conventions are a way to skip steps when writing things down.
If you're unsure about whether it's OK to take the shortcut, the safest thing is to go by the formal definition.




\section{The Use/Mention Distinction}
  \label{s:UseMention}

We have just talked a lot \emph{about} sentences.
So we should pause to explain an important, and very general, point.
This section rehashes some distinctions introduced above--- such as object vs. metalanguage--- but in a new light.



\subsection{Quotation Conventions}
  \label{sec:quotation}

Consider these two sentences:

\begin{earg}
  \item[\ex{use1}] Justin Trudeau is the Prime Minister.  
  \item[\ex{use2}] The expression `Justin Trudeau' is composed of two uppercase letters and eleven lowercase letters.
\end{earg}

When we want to talk about the Prime Minister, we \emph{use} his name as in \ref{use1}.
When we want to talk about the Prime Minister's name, we \emph{mention} that name, which we do by putting it in quotation marks as in \ref{use2}.
Similarly, I might say that you are reading a logic textbook, whereas `Logic' is the name of a 21st century American rapper. 

There is a general point here.
When we want to talk about things in the world, we just \emph{use} words.
When we want to talk about words, we \emph{mention} those words.
We need to indicate that we are mentioning them, rather than using them.
To do this, some convention is needed.
We can put them in quotation marks, display them centrally on the page, or come up with some other convention, such as corner quotes. 
Here is the convention that we will use:

\factoidbox{
  Quoted expressions are the \textit{canonical name} for the expression quoted.
}

For instance `ABC' is the name for the expression consisting of the first letter of the alphabet, followed by the second letter of the alphabet, followed by the third letter of the alphabet.

Consider the following sentence: `Justin Trudeau' is the Prime Minister.
That sentence says that some \emph{expression} is the Prime Minister.
Clearly, that's false: Canadian parliamentarians are too clever to appoint an expression as prime minister.
The \emph{man} is the Prime Minister; his \emph{name} isn't.
Conversely, this sentence:
  \begin{earg}
    \item[\ex{use3}] Justin Trudeau is composed of two uppercase letters and eleven lowercase letters. 
  \end{earg}
also says something false: Justin Trudeau is a man, composed mainly of a few chemical elements rather than letters. One final example:
  \begin{earg}
    \item[\ex{use4}] ``\,`Justin Trudeau'\,'' is the name of `Justin Trudeau'. 
  \end{earg}
On the left-hand-side, here, we have the name of a name. On the right hand side, we have a name. Perhaps this kind of sentence only occurs in logic textbooks, but it is true nonetheless.

It is important to contrast two other uses that quotation marks often have in other contexts: attribution and scare quotes.
These uses are connected.
For instance, in writing a paper, one might \textit{use} the words of another while nevertheless attributing those words to that author.
Here's a concrete example.
Say we are discussing Quine's ontology, and we want to say that Quine argues that positing merely possible objects, ``offends the aesthetic sense of us who have a taste for desert landscapes.''
The quoted words belong to Quine, and we want to make this clear to our reader.
Nevertheless, we are still \textit{using} Quine's words; we are not merely mentioning them, i.e., naming the string that he wrote.
Along these same lines, one might \textit{use} certain words to make a claim but without wanting to attribute that claim to oneself even though there is no one else to attribute that claim to.
For instance, one might claim that the song was ``ratchet'' to both use the slang term `ratchet' but without standing by that use.
This usage might suggest that others take the song to be ratchet, though we are not joining them in doing so.
There are many such examples along these and other lines, but this is not the primary way that we will be using quotation marks in this course.

It is often cumbersome to strictly adhere to the distinction between use and mention.
Indeed, in the preceding sections, we have mentioned symbols without always putting them in quotation marks.
The following subsections provide some justifications for doing so.





\subsection{Dropping Quotes}
  \label{sub:DropQuote}

We have taken uppercase letters to be the sentence letters of SL:
	$$A, B, C, Z, A_1, B_4, A_{25}, J_{375},\ldots$$
These are sentences of the object language SL.
They are not sentences of our metalanguage, i.e., mathematical English.
So we must not say, for example:

	\begin{earg}
    \item[\ex{use5}] $D$ is a sentence letter of SL.
	\end{earg}

Obviously, we are trying to come out with an English sentence that says something about the object language (SL), but `$D$' is a sentence of SL, and not part of English.
Put flatly, the sentences of SL \textit{do not} belong to our metalanguage, i.e., mathematical English.
So \ref{use5} is gibberish.
To take another example along the same lines, consider:

	\begin{earg}
    \item[\ex{use6}] Schnee ist wei\ss\ is a German sentence.
	\end{earg}

What we surely meant to say, in this case, is:

	\begin{earg}
    \item[\ex{use7}] `Schnee ist wei\ss' is a German sentence.
	\end{earg}

Equally, what we meant to say in \ref{use5} is:

	\begin{earg}
    \item[\ex{use8}] `$D$' is a sentence letter of SL.
	\end{earg}

Given how easy it was to guess that by \ref{use5} we really intended \ref{use8}, it is permissible to drop the quotes in \ref{use5}.
This is common practice, and a convenience we will indulge in throughout this course.
What matters is that such indulgences don't lead to real ambiguities and that, as a result, it is always possible and easy to reconstruct the intended claim.




\subsection{Corner Quotes}
  \label{sec:Corner Quotes}

Recall from $\S\ref{sec:wff}$ the manner in which we used metavariables to provide a recursive definition of the wffs of SL.
This included such claims as: If $\metaA{}$ is a wff, then $\enot \metaA{}$ is a wff.
We are now in a position to take issue with this definition.
For instance, since $\metaA$ is a sentence letter, we know that $\metaA$ is a wff. 
However, strictly speaking, we cannot claim that $\enot \metaA$ is a wff since in this instance we are using the expression `$\enot A$' rather than mentioning it.

It is natural to suspect that all we were missing were the quotes, since it is true to say that `$\enot A$' is a wff.
However, we don't just want to talk about `$A$' and its negation; we want to talk about \textit{any} wff and its negation, as well as conjunctions, disjuncts, and so on.
But this raises a problem, since we cannot achieve the desired generality by merely replacing `$A$' with a metavariable.
This is because it is false to say that `$\enot \metaA{}$' is a wff.
Rather, the symbol `$\metaA{}$' belongs to our metalanguage which is mathematical English, not to our object language SL.

Enter Quine quotes, also called \textit{corner quotes}.
What we need to say is that the result of taking any wff $\metaA{}$ and putting the negation sign `$\enot$' in front of it is also a wff.
To do this, we take $\corner{\enot \metaA{}}$ to name the result of concatenating `$\enot$' with the value of $\metaA$ which is a wff. 
Similarly, $\corner{\metaA{} \eand \metaB{}}$ names the result of concatenating the value of $\metaA{}$ with the conjunction symbol `$\eand$' and the value of $\metaB{}$.
We may something analogues for each of the connectives that we have considered.
In doing so, we may restate the definition of a wff with this new tool:

\begin{enumerate}
  \item Every atomic sentence is a wff.
  \item If \metaA{} and \metaB{} are any wffs, then:
    \begin{enumerate}
      \item $\corner{\enot\metaA{}}$ is a wff;
      \item $\corner{(\metaA{}\eand\metaB{})}$ is a wff;
      \item $\corner{(\metaA{}\eor\metaB{})}$ is a wff;
      \item $\corner{(\metaA{}\eif\metaB{})}$ is a wff; and
      \item $\corner{(\metaA{}\eiff\metaB{})}$ is a wff.
    \end{enumerate}
  \item Nothing else is a wff.
\end{enumerate}

This is all very pedantic, but it is important if our definition of a wff is going to do what we want it to do.
Nevertheless, once we have understood what is at stake, and have provided a cleaned up version of our definition of a wff, we may go right back to speaking of `$\enot \metaA{}$' as if it were a wff and doing something similar for the other connectives. 
The reason that we can get away with this is that it is easy to reconstruct what we had in mind: what we \textit{really} mean to say is that given any value for $\metaA{}$ (i.e., some wff), the result of concatenating `$\enot$' with that value is also a wff.
Instead of saying all of this, we may indulge in some loose talk by saying that $\enot \metaA{}$ is a wff, claiming that $\enot \metaA{}$ is a wff. 
Given this important caveat, we may make use of the original definition of a wff, bearing in mind what it is that we really intend.





\subsection{Quotation Conventions for Arguments}
  \label{sub:QuoteArguments}

One of the main purposes of using SL is to study arguments, and that will be our concern in chapter \ref{ch.TruthTables}.
In English, the premises of an argument are often expressed by individual sentences, and the conclusion by a further sentence.
Since we can regiment English sentences in SL, we can also regiment English arguments using SL by regiment each of the sentences used in an English argument.
However, SL itself has no way to flag some sentences as the \emph{premises} and another sentence as the \emph{conclusion} of the argument.
In contrast, English uses words like `so', `therefore', etc., to mark that a sentence is the conclusion of an argument.

%An obvious thought would be to add a new symbol to the \emph{object} language of SL itself, which we could use to separate the premises from the conclusion of an argument. However, adding a new symbol to our object language would add significant complexity to that language, since that symbol would require an official syntax.\footnote{\emph{The following footnote should be read only after you have finished the entire book!} And it would require a semantics. Here, there are deep barriers concerning the semantics. First: an object-language symbol which adequately expressed `therefore' for SL would not be truth-functional. (\emph{Exercise}: why?) Second: a paradox known as `validity Curry' shows that FOL itself \emph{cannot} be augmented with an adequate, object-language `therefore'.} 

So, we need another bit of notation. Suppose we want to regiment the premises of an argument with $\metaA{}_1$, \dots,~$\metaA{}_n$ and the conclusion with $\metaC{}$. Then we will write:
$$\metaA{}_1, \ldots, \metaA{}_n \; \therefore \; \metaC{}$$
The role of the symbol `$\therefore$' is simply to indicate which sentences are the premises and which is the conclusion.
Strictly speaking, this extra notation is unnecessary.
After all, we could always just write things down long-hand, saying: the premises of the argument are well symbolised by $\metaA{}_1, \ldots \metaA{}_n$, and the conclusion of the argument is well symbolised by $\metaC{}$.
But having some convention will save us some time.
The particular convention we chose was fairly arbitrary.
After all, an equally good convention would have been to underline the conclusion of the argument.
Even so, this is not the convention that we will use.

It is important to stress that, like the metavariables, the symbol `$\therefore$' will not be a part of the object language SL, but rather a part of the metalanguage.
As such, one might think that we would need to put quote-marks around the SL-sentences which flank it.
That is a sensible thought, but adding these quote-marks would make things harder to read.
Moreover--- and as above--- recall that \emph{we} are stipulating some new conventions.
So, we can simply stipulate that these quote-marks are unnecessary.
That is, we can simply write
$$A, A \eif B \; \therefore \; B$$
without any quotation marks, to indicate an argument in SL whose premises are `$A$' and `$A \eif B$' and whose conclusion is `$B$'.
It can take some practice for these conventions to sink into place.
The problem sets will provide an opportunity, but don't limit your practice to the problem sets alone.
Below are a number of further practice problems for the chapter.



\iffalse

\practiceproblems

\solutions
\problempart Using the symbolization key given, regiment each English-language sentence in SL.
\label{pr.monkeysuits}
\begin{ekey}
\item[M:] Those creatures are men in suits. 
\item[C:] Those creatures are chimpanzees. 
\item[G:] Those creatures are gorillas.
\end{ekey}
\begin{earg}
\item Those creatures are not men in suits.
\item Those creatures are men in suits, or they are not.
\item Those creatures are either gorillas or chimpanzees.
\item Those creatures are neither gorillas nor chimpanzees.
\item If those creatures are chimpanzees, then they are neither gorillas nor men in suits.
\item Unless those creatures are men in suits, they are either chimpanzees or they are gorillas.
\end{earg}


\problempart Using the symbolization key given, regiment each English-language sentence into SL.
\begin{ekey}
\item[A:] Mister Ace was murdered.
\item[B:] The butler did it.
\item[C:] The cook did it.
\item[D:] The Duchess is lying.
\item[E:] Mister Edge was murdered.
\item[F:] The murder weapon was a frying pan.
\end{ekey}
\begin{earg}
\item Either Mister Ace or Mister Edge was murdered.
\item If Mister Ace was murdered, then the cook did it.
\item If Mister Edge was murdered, then the cook did not do it.
\item Either the butler did it, or the Duchess is lying.
\item The cook did it only if the Duchess is lying.
\item If the murder weapon was a frying pan, then the culprit must have been the cook.
\item If the murder weapon was not a frying pan, then the culprit was either the cook or the butler.
\item Mister Ace was murdered if and only if Mister Edge was not murdered.
\item The Duchess is lying, unless it was Mister Edge who was murdered.
\item If Mister Ace was murdered, he was done in with a frying pan.
\item Since the cook did it, the butler did not.
\item Of course the Duchess is lying!
\end{earg}



\solutions
\problempart Using the symbolization key given, regiment each English-language sentence into SL.
\label{pr.avacareer}
\begin{ekey}
\item[E$_1$:] Ava is an electrician.
\item[E$_2$:] Harrison is an electrician.
\item[F$_1$:] Ava is a firefighter.
\item[F$_2$:] Harrison is a firefighter.
\item[S$_1$:] Ava is satisfied with her career.
\item[S$_2$:] Harrison is satisfied with his career.
\end{ekey}
\begin{earg}
\item Ava and Harrison are both electricians.
\item If Ava is a firefighter, then she is satisfied with her career.
\item Ava is a firefighter, unless she is an electrician.
\item Harrison is an unsatisfied electrician.
\item Neither Ava nor Harrison is an electrician.
\item Both Ava and Harrison are electricians, but neither of them find it satisfying.
\item Harrison is satisfied only if he is a firefighter.
\item If Ava is not an electrician, then neither is Harrison, but if she is, then he is too.
\item Ava is satisfied with her career if and only if Harrison is not satisfied with his.
\item If Harrison is both an electrician and a firefighter, then he must be satisfied with his work.
\item It cannot be that Harrison is both an electrician and a firefighter.
\item Harrison and Ava are both firefighters if and only if neither of them is an electrician.
\end{earg}




\solutions
\problempart
\label{pr.spies}
Give a symbolization key and regiment the following sentences in SL.
\begin{earg}
\item Alice and Bob are both spies.
\item If either Alice or Bob is a spy, then the code has been broken.
\item If neither Alice nor Bob is a spy, then the code remains unbroken.
\item The German embassy will be in an uproar, unless someone has broken the code.
\item Either the code has been broken or it has not, but the German embassy will be in an uproar regardless.
\item Either Alice or Bob is a spy, but not both.
\end{earg}

\solutions
\problempart
\label{pr.gregorbaseball}
Give a symbolization key and regiment the following sentences in SL.
\begin{earg}
\item If Gregor plays first base, then the team will lose.
\item The team will lose unless there is a miracle.
\item The team will either lose or it won't, but Gregor will play first base regardless.
\item Gregor's mom will bake cookies if and only if Gregor plays first base.
\item If there is a miracle, then Gregor's mom will not bake cookies.
\end{earg}


\problempart
\label{pr.choresSL}
For each argument, write a symbolization key and regiment the argument as well as possible in SL.
\begin{earg}
\item If Dorothy plays the piano in the morning, then Roger wakes up cranky. Dorothy plays piano in the morning unless she is distracted. So if Roger does not wake up cranky, then Dorothy must be distracted.
\item It will either rain or snow on Tuesday. If it rains, Neville will be sad. If it snows, Neville will be cold. Therefore, Neville will either be sad or cold on Tuesday.
\item If Zoog remembered to do his chores, then things are clean but not neat. If he forgot, then things are neat but not clean. Therefore, things are either neat or clean --- but not both.
\end{earg}



\problempart
\label{HW2.A}
For each, indicate (yes/no) whether it is a sentence of SL.
\begin{earg}
		\item $P_{2}$
		\item if $P$, then $Q$
		\item $(P \eor Q \eand R)$
		\item $((P \eand (P \eand P)) \eif P)$
		\item $(p \eif q)$
		\item $(P \eor Q) \eor R)$
		\item $\enot \enot \enot \enot P$
		\item $(\Sigma \eand \Phi)$
	\end{earg}

\solutions
\problempart
\label{pr.wiffSL}
For each of the following: (a) Is it, by the strictest formal standards, a sentence of SL? (b) Is it an acceptable way to write down a sentence of SL, allowing for our notational conventions?
\begin{earg}
\item $(A)$
\item $J_{374} \eor \enot J_{374}$
\item $\enot \enot \enot \enot F$
\item $\enot \eand S$
\item $(G \eand \enot G)$
\item $\metaA{} \eif \metaA{}$
\item $(A \eif (A \eand \enot F)) \eor (D \eiff E)$
\item $[(Z \eiff S) \eif W] \eand [J \eor X]$
\item $(F \eiff \enot D \eif J) \eor (C \eand D)$
\end{earg}



\problempart
\begin{earg}
\item Are there any wffs of SL that contain no sentence letters? Why or why not?
%\item In the chapter, we symbolized an \emph{exclusive or} using \eor, \eand, and \enot. How could you regiment an \emph{exclusive or} using only two connectives? Is there any way to regiment an \emph{exclusive or} using only one connective?
\end{earg}

\problempart
\label{HW2.B}
For each, first, indicate whether it is a conjunction, disjunction, conditional, biconditional, negation, or none of these.

Second, unless the answer is none of these, identify its relevant propositional components. (For example, if it is a conjunction, identify the conjuncts; etc.) In the case of complex propositions, you do not need to identify components of the components. (For example, if one of the conjuncts is itself a conjunction, you dont need to identify the conjuncts of that conjunct.)

	\begin{earg}
		\item If your computer crashes and you dont have a backup, then youll have to work all night or ask for an extension.
		\item If the blue team scores, the crowd will not cheer.
		\item Im very hungry and if I have to wait any longer, Im going to start getting angry.
		\item I did not tell Mother or Father.
	\end{earg}
	
\problempart
\label{HW2.C}
Regiment these English sentences in SL, using this symbolization key:
\begin{ekey}
\item[P:] John will get a good grade.
\item[Q:] John will get a good job.
\item[R:] John's mother learns John's grade.
\item[S:] John will be in trouble.
\end{ekey}
	\begin{earg}
		\item If John doesnt get a good grade, he wont get a good job.
		\item If John doesnt get a good grade, then if his mother learns his grade, hell be in
trouble.
		\item John will be in trouble, but he will get a good grade.
		\item If his grade isn't good, John won't be in trouble unless his mother learns his grade.
	\end{earg}

	
\problempart
\label{HW2.D}

Regiment these SL sentences in English, using this symbolization key:
\begin{ekey}
\item[P:] logic is awesome
\item[Q:] opera is sexy
\item[R:] the moon is made of cheese
\item[S:] every PHIL 220 student will get an A
\end{ekey}
	\begin{earg}
		\item $(P \eif \enot Q)$
		\item $(S \eif (P \eor R))$
		\item $(Q \eand \enot S)$
		\item $\enot \enot Q$
		\item $(Q \eiff R)$
	\end{earg}
	
\fi
